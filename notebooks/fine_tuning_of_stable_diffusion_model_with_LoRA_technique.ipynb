{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Dependencies**"
      ],
      "metadata": {
        "id": "ANyzpl2v_LjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ9BC-j5_Fto",
        "outputId": "8ffe76bb-a586-4baf-c6af-8397378567b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 60371, done.\u001b[K\n",
            "remote: Counting objects: 100% (369/369), done.\u001b[K\n",
            "remote: Compressing objects: 100% (241/241), done.\u001b[K\n",
            "remote: Total 60371 (delta 222), reused 214 (delta 115), pack-reused 60002\u001b[K\n",
            "Receiving objects: 100% (60371/60371), 41.81 MiB | 13.28 MiB/s, done.\n",
            "Resolving deltas: 100% (43926/43926), done.\n",
            "/content/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/diffusers/examples/text_to_image\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd diffusers\n",
        "!pip install . -q\n",
        "%cd examples/text_to_image\n",
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_bAyxkvoPsD",
        "outputId": "3313de64-51f8-4a89-b5ac-fcbfc036bc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjjaC5eToQMS",
        "outputId": "63b71e3b-a4a7-411d-d364-2c6aba1f8210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4W_3UZYG0wG",
        "outputId": "b3d7ebdb-ed9b-46e7-a553-64df3f1507e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "0Oo9tXd-qYrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
        "os.environ[\"HF_DATASETS_OFFLINE\"] = '1'\n",
        "os.environ[\"DIFFUSERS_OFFLINE\"] = '1'\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "id": "_d755fsGo5iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_path = \"/content/drive/MyDrive/Datasets/base_sd_model\"\n",
        "dataset_path = \"/content/drive/MyDrive/Datasets/5000_datasets\"\n",
        "output_dir_path = \"/content/drive/MyDrive/Datasets/lora_model_weights\""
      ],
      "metadata": {
        "id": "14OTc972o6nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg2s1zqLrl6L",
        "outputId": "60bb6091-90de-4610-d8ec-3ae60c50cb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md\t       requirements.txt\t\t    train_text_to_image_lora.py\n",
            "README_sdxl.md\t       test_text_to_image_lora.py   train_text_to_image_lora_sdxl.py\n",
            "requirements_flax.txt  test_text_to_image.py\t    train_text_to_image.py\n",
            "requirements_sdxl.txt  train_text_to_image_flax.py  train_text_to_image_sdxl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=$base_model_path \\\n",
        "  --dataset_name=$dataset_path \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --resolution=512 \\\n",
        "  --center_crop \\\n",
        "  --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --num_train_epochs=5 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --learning_rate=1e-06 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --output_dir=$output_dir_path \\\n",
        "  --checkpointing_steps=1000"
      ],
      "metadata": {
        "id": "j-5aTGkGDQvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1adbac-74c9-4a5d-d0a7-b7f947a8827c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-20 10:47:41.059555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-20 10:47:41.059599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-20 10:47:41.061017: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-20 10:47:42.212946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/20/2024 10:47:42 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "{'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "04/20/2024 10:50:30 - INFO - __main__ - ***** Running training *****\n",
            "04/20/2024 10:50:30 - INFO - __main__ -   Num examples = 5000\n",
            "04/20/2024 10:50:30 - INFO - __main__ -   Num Epochs = 5\n",
            "04/20/2024 10:50:30 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "04/20/2024 10:50:30 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "04/20/2024 10:50:30 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
            "04/20/2024 10:50:30 - INFO - __main__ -   Total optimization steps = 6250\n",
            "Steps:  16% 1000/6250 [31:45<2:38:20,  1.81s/it, lr=1e-6, step_loss=0.0286]04/20/2024 11:22:15 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000\n",
            "04/20/2024 11:22:24 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000/model.safetensors\n",
            "04/20/2024 11:22:24 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000/optimizer.bin\n",
            "04/20/2024 11:22:24 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000/scheduler.bin\n",
            "04/20/2024 11:22:24 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000/sampler.bin\n",
            "04/20/2024 11:22:24 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000/scaler.pt\n",
            "04/20/2024 11:22:24 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000/random_states_0.pkl\n",
            "Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000/pytorch_lora_weights.safetensors\n",
            "04/20/2024 11:22:25 - INFO - __main__ - Saved state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-1000\n",
            "Steps:  32% 2000/6250 [1:03:21<2:12:57,  1.88s/it, lr=1e-6, step_loss=0.174]04/20/2024 11:53:51 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000\n",
            "04/20/2024 11:53:59 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000/model.safetensors\n",
            "04/20/2024 11:54:00 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000/optimizer.bin\n",
            "04/20/2024 11:54:00 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000/scheduler.bin\n",
            "04/20/2024 11:54:00 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000/sampler.bin\n",
            "04/20/2024 11:54:00 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000/scaler.pt\n",
            "04/20/2024 11:54:00 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000/random_states_0.pkl\n",
            "Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000/pytorch_lora_weights.safetensors\n",
            "04/20/2024 11:54:00 - INFO - __main__ - Saved state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-2000\n",
            "Steps:  48% 3000/6250 [1:34:59<1:41:18,  1.87s/it, lr=1e-6, step_loss=0.0931]04/20/2024 12:25:29 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000\n",
            "04/20/2024 12:25:41 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000/model.safetensors\n",
            "04/20/2024 12:25:41 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000/optimizer.bin\n",
            "04/20/2024 12:25:41 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000/scheduler.bin\n",
            "04/20/2024 12:25:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000/sampler.bin\n",
            "04/20/2024 12:25:41 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000/scaler.pt\n",
            "04/20/2024 12:25:41 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000/random_states_0.pkl\n",
            "Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000/pytorch_lora_weights.safetensors\n",
            "04/20/2024 12:25:41 - INFO - __main__ - Saved state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-3000\n",
            "Steps:  64% 4000/6250 [2:06:39<1:11:38,  1.91s/it, lr=1e-6, step_loss=0.112]04/20/2024 12:57:09 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000\n",
            "04/20/2024 12:57:18 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000/model.safetensors\n",
            "04/20/2024 12:57:18 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000/optimizer.bin\n",
            "04/20/2024 12:57:18 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000/scheduler.bin\n",
            "04/20/2024 12:57:18 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000/sampler.bin\n",
            "04/20/2024 12:57:18 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000/scaler.pt\n",
            "04/20/2024 12:57:18 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000/random_states_0.pkl\n",
            "Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000/pytorch_lora_weights.safetensors\n",
            "04/20/2024 12:57:18 - INFO - __main__ - Saved state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-4000\n",
            "Steps:  80% 5000/6250 [2:38:14<40:33,  1.95s/it, lr=1e-6, step_loss=0.135]04/20/2024 13:28:44 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000\n",
            "04/20/2024 13:28:53 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000/model.safetensors\n",
            "04/20/2024 13:28:53 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000/optimizer.bin\n",
            "04/20/2024 13:28:53 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000/scheduler.bin\n",
            "04/20/2024 13:28:53 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000/sampler.bin\n",
            "04/20/2024 13:28:53 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000/scaler.pt\n",
            "04/20/2024 13:28:53 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000/random_states_0.pkl\n",
            "Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000/pytorch_lora_weights.safetensors\n",
            "04/20/2024 13:28:53 - INFO - __main__ - Saved state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-5000\n",
            "Steps:  96% 6000/6250 [3:09:47<07:43,  1.86s/it, lr=1e-6, step_loss=0.219]04/20/2024 14:00:17 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000\n",
            "04/20/2024 14:00:28 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000/model.safetensors\n",
            "04/20/2024 14:00:28 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000/optimizer.bin\n",
            "04/20/2024 14:00:28 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000/scheduler.bin\n",
            "04/20/2024 14:00:28 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000/sampler.bin\n",
            "04/20/2024 14:00:28 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000/scaler.pt\n",
            "04/20/2024 14:00:28 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000/random_states_0.pkl\n",
            "Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000/pytorch_lora_weights.safetensors\n",
            "04/20/2024 14:00:29 - INFO - __main__ - Saved state to /content/drive/MyDrive/Datasets/lora_model_weights/checkpoint-6000\n",
            "Steps: 100% 6250/6250 [3:17:53<00:00,  1.82s/it, lr=1e-6, step_loss=0.0688]Model weights saved in /content/drive/MyDrive/Datasets/lora_model_weights/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 6250/6250 [3:17:53<00:00,  1.90s/it, lr=1e-6, step_loss=0.0688]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SciQtG5BHka0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}