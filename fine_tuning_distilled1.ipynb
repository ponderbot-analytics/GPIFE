{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lUTSl_efs3m",
        "outputId": "959d1281-a98f-40fc-db93-547d24dfbe28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 60053, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 60053 (delta 14), reused 14 (delta 3), pack-reused 60020\u001b[K\n",
            "Receiving objects: 100% (60053/60053), 41.16 MiB | 18.53 MiB/s, done.\n",
            "Resolving deltas: 100% (43730/43730), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmXdmkFzf5SJ",
        "outputId": "38c4847b-0c40-4563-d9f3-77bb8fb7a847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h7y0hSy8gALo",
        "outputId": "5e86089f-4bd4-4c5d-8cb7-307465feadc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd diffusers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHlAmT8LgDRQ",
        "outputId": "4b53ed5e-3f95-423c-9024-e02b2d5c0b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install . -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqyHfob3gFvs",
        "outputId": "5fad369b-0426-4358-9595-20fd744120af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd examples/text_to_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eDU4_K8gH8L",
        "outputId": "ef3d4e3b-f6f1-479f-b2dd-609f62a4183d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusers/examples/text_to_image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6odKSNokgKZo",
        "outputId": "1784240d-571a-441a-e704-9f742f918147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m87ma3RQgSJ2",
        "outputId": "b25a4788-ec31-4fdc-991a-ed8e9eb055be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login"
      ],
      "metadata": {
        "id": "PPushUAHgVAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
        "os.environ[\"HF_DATASETS_OFFLINE\"] = '1'\n",
        "os.environ[\"DIFFUSERS_OFFLINE\"] = '1'\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "id": "c-y_WdZ1oxP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Datasets/sdp_1_datasets\"\n",
        "model_path = \"/content/drive/MyDrive/Datasets/sdp_1_model_distilled\""
      ],
      "metadata": {
        "id": "o7kxfT8Roz2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=$model_path \\\n",
        "  --dataset_name=$dataset_path \\\n",
        "  --resolution=128 --center_crop --random_flip \\\n",
        "  --num_train_epochs=50 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --checkpointing_steps=1000 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --learning_rate=1e-05 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --output_dir=\"fine_tuned_model\" \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSbXqYz_o2kc",
        "outputId": "36678e7e-93e9-43de-a5a4-ddc28b821b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-13 15:25:40.472872: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-13 15:25:40.472923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-13 15:25:40.474243: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-13 15:25:41.759024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/13/2024 15:25:42 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "{'rescale_betas_zero_snr', 'clip_sample_range', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "04/13/2024 15:25:47 - INFO - __main__ - ***** Running training *****\n",
            "04/13/2024 15:25:47 - INFO - __main__ -   Num examples = 100\n",
            "04/13/2024 15:25:47 - INFO - __main__ -   Num Epochs = 50\n",
            "04/13/2024 15:25:47 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "04/13/2024 15:25:47 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "04/13/2024 15:25:47 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
            "04/13/2024 15:25:47 - INFO - __main__ -   Total optimization steps = 1250\n",
            "Steps:  80% 1000/1250 [14:00<03:28,  1.20it/s, lr=1e-5, step_loss=0.108]04/13/2024 15:39:47 - INFO - accelerate.accelerator - Saving current state to fine_tuned_model/checkpoint-1000\n",
            "Configuration saved in fine_tuned_model/checkpoint-1000/unet/config.json\n",
            "Model weights saved in fine_tuned_model/checkpoint-1000/unet/diffusion_pytorch_model.safetensors\n",
            "04/13/2024 15:40:12 - INFO - accelerate.checkpointing - Optimizer state saved in fine_tuned_model/checkpoint-1000/optimizer.bin\n",
            "04/13/2024 15:40:12 - INFO - accelerate.checkpointing - Scheduler state saved in fine_tuned_model/checkpoint-1000/scheduler.bin\n",
            "04/13/2024 15:40:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in fine_tuned_model/checkpoint-1000/sampler.bin\n",
            "04/13/2024 15:40:12 - INFO - accelerate.checkpointing - Gradient scaler state saved in fine_tuned_model/checkpoint-1000/scaler.pt\n",
            "04/13/2024 15:40:12 - INFO - accelerate.checkpointing - Random states saved in fine_tuned_model/checkpoint-1000/random_states_0.pkl\n",
            "04/13/2024 15:40:12 - INFO - __main__ - Saved state to fine_tuned_model/checkpoint-1000\n",
            "Steps: 100% 1250/1250 [17:58<00:00,  1.07it/s, lr=1e-5, step_loss=0.156] \n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /content/drive/MyDrive/Datasets/sdp_1_model_distilled.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:00<00:00, 15.96it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /content/drive/MyDrive/Datasets/sdp_1_model_distilled.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of /content/drive/MyDrive/Datasets/sdp_1_model_distilled.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  8.47it/s]\u001b[A\n",
            "Loading pipeline components...:  57% 4/7 [00:12<00:00,  8.47it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /content/drive/MyDrive/Datasets/sdp_1_model_distilled.\n",
            "\n",
            "Loading pipeline components...: 100% 7/7 [00:17<00:00,  2.46s/it]\n",
            "Configuration saved in fine_tuned_model/vae/config.json\n",
            "Model weights saved in fine_tuned_model/vae/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in fine_tuned_model/unet/config.json\n",
            "Model weights saved in fine_tuned_model/unet/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in fine_tuned_model/scheduler/scheduler_config.json\n",
            "Configuration saved in fine_tuned_model/model_index.json\n",
            "Steps: 100% 1250/1250 [18:53<00:00,  1.10it/s, lr=1e-5, step_loss=0.156]\n"
          ]
        }
      ]
    }
  ]
}